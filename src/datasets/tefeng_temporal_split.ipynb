{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ta-Feng"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import packages and define constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/users/tr.zaiqm/mycode/tr_rec/configs/\n",
      "/users/tr.zaiqm/mycode/tr_rec/datasets/\n",
      "/users/tr.zaiqm/mycode/tr_rec/checkpoints/\n",
      "/users/tr.zaiqm/mycode/tr_rec/results/\n",
      "/users/tr.zaiqm/mycode/tr_rec/samples/\n",
      "/users/tr.zaiqm/mycode/tr_rec/logs/\n",
      "/users/tr.zaiqm/mycode/tr_rec/runs/\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import sys\n",
    "\n",
    "sys.path.append(\"../\")\n",
    "import random\n",
    "from pandas.core.frame import DataFrame\n",
    "import sklearn\n",
    "from utils.unigramTable import UnigramTable\n",
    "\n",
    "\n",
    "DEFAULT_USER_COL = \"user_ids\"\n",
    "DEFAULT_ITEM_COL = \"item_ids\"\n",
    "DEFAULT_ORDER_COL = \"order_ids\"\n",
    "DEFAULT_RATING_COL = \"ratings\"\n",
    "DEFAULT_LABEL_COL = \"label\"\n",
    "DEFAULT_TIMESTAMP_COL = \"timestamp\"\n",
    "DEFAULT_PREDICTION_COL = \"prediction\"\n",
    "DEFAULT_FLAG_COL = \"flag\"\n",
    "data_base_dir = \"../../datasets/tafeng/\"\n",
    "\n",
    "\n",
    "test_percents = [0.1, 0.15, 0.2, 0.25, 0.3]\n",
    "# validate percent just choose the same percent in the training set\n",
    "\n",
    "negative_size = 100\n",
    "\n",
    "min_u_c = 20  # items which were purcharsed by at least min_u_c users\n",
    "min_i_c = 30  # users buy at least min_i_c items\n",
    "min_o_c = 10  ##users have at least min_o_c orders"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## load full data to sequence DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "405742\n",
      "464118\n"
     ]
    }
   ],
   "source": [
    "original_train_file = data_base_dir + \"train.txt\"\n",
    "original_test_file = data_base_dir + \"test.txt\"\n",
    "prior_test_df = DataFrame(columns=[\"order_id\", \"user_id\", \"time\", \"item_id\"])\n",
    "prior_train_df = DataFrame(\n",
    "    columns=[\"order_id\", \"user_id\", \"time\", \"item_id\"]\n",
    ")  # initial dataframe\n",
    "interaction_list = []\n",
    "with open(original_train_file) as ori_test_df:\n",
    "    for line in ori_test_df:\n",
    "        temp_list = line.replace(\"\\n\", \"\\t\").split(\n",
    "            \"\\t\"\n",
    "        )  # replace '\\n' in the end of the line by '\\t'\n",
    "        # split line by '\\t'\n",
    "        # store splited items in a list\n",
    "        order_id = temp_list[0]\n",
    "        item_ids_list = temp_list[1:-3]  # itemids\n",
    "        time_order = temp_list[-2].replace(\"-\", \"\")\n",
    "        user_id = temp_list[-3]\n",
    "        for item_id in item_ids_list:\n",
    "            interaction_list.append(\n",
    "                [order_id, user_id, item_id, \"train\", \"1\", time_order]\n",
    "            )\n",
    "    print(len(interaction_list))\n",
    "with open(original_test_file) as ori_test_df:\n",
    "    for line in ori_test_df:\n",
    "        temp_list = line.replace(\"\\n\", \"\\t\").split(\n",
    "            \"\\t\"\n",
    "        )  # replace '\\n' in the end of the line by '\\t'\n",
    "        # split line by '\\t'\n",
    "        # store splited items in a list\n",
    "        order_id = temp_list[0]\n",
    "        item_ids_list = temp_list[1:-3]  # itemids\n",
    "        time_order = temp_list[-2].replace(\"-\", \"\")\n",
    "        user_id = temp_list[-3]\n",
    "        for item_id in item_ids_list:\n",
    "            interaction_list.append(\n",
    "                [order_id, user_id, item_id, \"train\", \"1\", time_order]\n",
    "            )\n",
    "    print(len(interaction_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(464118, 6)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "interactions = np.array(interaction_list)\n",
    "interactions.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_data = pd.DataFrame(\n",
    "    data={\n",
    "        DEFAULT_ORDER_COL: interactions[:, 0],\n",
    "        DEFAULT_USER_COL: interactions[:, 1],\n",
    "        DEFAULT_ITEM_COL: interactions[:, 2],\n",
    "        DEFAULT_FLAG_COL: interactions[:, 3],\n",
    "        DEFAULT_RATING_COL: interactions[:, 4],\n",
    "        DEFAULT_TIMESTAMP_COL: interactions[:, 5],\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>order_ids</th>\n",
       "      <th>user_ids</th>\n",
       "      <th>item_ids</th>\n",
       "      <th>flag</th>\n",
       "      <th>ratings</th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>00261647</td>\n",
       "      <td>4710852001013</td>\n",
       "      <td>train</td>\n",
       "      <td>1</td>\n",
       "      <td>20001214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>00261647</td>\n",
       "      <td>4711128778882</td>\n",
       "      <td>train</td>\n",
       "      <td>1</td>\n",
       "      <td>20001214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>00261647</td>\n",
       "      <td>4710467551224</td>\n",
       "      <td>train</td>\n",
       "      <td>1</td>\n",
       "      <td>20001214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>00261647</td>\n",
       "      <td>4902775015356</td>\n",
       "      <td>train</td>\n",
       "      <td>1</td>\n",
       "      <td>20001214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>00261647</td>\n",
       "      <td>4710362500051</td>\n",
       "      <td>train</td>\n",
       "      <td>1</td>\n",
       "      <td>20001214</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  order_ids  user_ids       item_ids   flag ratings  timestamp\n",
       "0         0  00261647  4710852001013  train       1  20001214 \n",
       "1         0  00261647  4711128778882  train       1  20001214 \n",
       "2         0  00261647  4710467551224  train       1  20001214 \n",
       "3         0  00261647  4902775015356  train       1  20001214 \n",
       "4         0  00261647  4710362500051  train       1  20001214 "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Row data staticstics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(464118, 77202, 9238, 7973)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_interact = len(full_data.index)\n",
    "n_orders = full_data[DEFAULT_ORDER_COL].nunique()\n",
    "n_users = full_data[DEFAULT_USER_COL].nunique()\n",
    "n_items = full_data[DEFAULT_ITEM_COL].nunique()\n",
    "(n_interact, n_orders, n_users, n_items)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save these sequence data to csv files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_raw_seq_to_files(data, data_base_dir, suff_str=\"full_raw\"):\n",
    "    data.to_csv(data_base_dir + \"data/ta-feng_\" + str(suff_str) + \".csv\")\n",
    "    print(\"Data saving to file:\", data_base_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data saving to file: ../../datasets/ta-feng/\n"
     ]
    }
   ],
   "source": [
    "save_raw_seq_to_files(full_data, data_base_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## load the seqence data from file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_raw_seq_from_files(data_base_dir, suff_str=\"full_raw\"):\n",
    "    print(\"Loading data from:\", data_base_dir)\n",
    "    loaded = pd.read_csv(\n",
    "        data_base_dir + \"data/ta-feng_\" + str(suff_str) + \".csv\", index_col=0\n",
    "    )\n",
    "    return loaded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data from: ../../datasets/ta-feng/\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>order_ids</th>\n",
       "      <th>user_ids</th>\n",
       "      <th>item_ids</th>\n",
       "      <th>flag</th>\n",
       "      <th>ratings</th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>261647</td>\n",
       "      <td>4710852001013</td>\n",
       "      <td>train</td>\n",
       "      <td>1</td>\n",
       "      <td>20001214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>261647</td>\n",
       "      <td>4711128778882</td>\n",
       "      <td>train</td>\n",
       "      <td>1</td>\n",
       "      <td>20001214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>261647</td>\n",
       "      <td>4710467551224</td>\n",
       "      <td>train</td>\n",
       "      <td>1</td>\n",
       "      <td>20001214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>261647</td>\n",
       "      <td>4902775015356</td>\n",
       "      <td>train</td>\n",
       "      <td>1</td>\n",
       "      <td>20001214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>261647</td>\n",
       "      <td>4710362500051</td>\n",
       "      <td>train</td>\n",
       "      <td>1</td>\n",
       "      <td>20001214</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   order_ids  user_ids       item_ids   flag  ratings  timestamp\n",
       "0          0    261647  4710852001013  train        1   20001214\n",
       "1          0    261647  4711128778882  train        1   20001214\n",
       "2          0    261647  4710467551224  train        1   20001214\n",
       "3          0    261647  4902775015356  train        1   20001214\n",
       "4          0    261647  4710362500051  train        1   20001214"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_data = load_raw_seq_from_files(data_base_dir)\n",
    "full_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "order_ids             9999\n",
       "user_ids          20002000\n",
       "item_ids     9789578032880\n",
       "flag                 train\n",
       "ratings                  1\n",
       "timestamp         20010228\n",
       "dtype: object"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_data.max()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test the integrity of the saved data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(464118, 77202, 9238, 7973)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_interact = len(full_data.index)\n",
    "n_orders = full_data[DEFAULT_ORDER_COL].nunique()\n",
    "n_users = full_data[DEFAULT_USER_COL].nunique()\n",
    "n_items = full_data[DEFAULT_ITEM_COL].nunique()\n",
    "(n_interact, n_orders, n_users, n_items)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## negative sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feed_neg_sample(eval_df, negative_num, item_sampler):\n",
    "    print(\"sampling negative items...\")\n",
    "    interact_status = eval_df.groupby([\"user_ids\"])[\"item_ids\"].apply(set).reset_index()\n",
    "    total_interact = pd.DataFrame(\n",
    "        {\"user_ids\": [], \"item_ids\": [], \"ratings\": []}, dtype=np.long\n",
    "    )\n",
    "    for index, user_items in interact_status.iterrows():\n",
    "        u = int(user_items[\"user_ids\"])\n",
    "        items = set(user_items[\"item_ids\"])  # item set for user u\n",
    "        n_items = len(items)  # number of positive item for user u\n",
    "        sample_neg_items = set(\n",
    "            item_sampler.sample(negative_num + n_items, 1, True)\n",
    "        )  # first sample negative_num+n_items items\n",
    "        sample_neg_items = list(sample_neg_items - items)[:negative_num]\n",
    "        # filter the positive items and truncate the first negative_num\n",
    "        #     print(len(sample_neg_items))\n",
    "        tp_items = np.append(list(items), sample_neg_items)\n",
    "        #     print(len(tp_items))\n",
    "\n",
    "        tp_users = np.array([1] * (negative_num + n_items), dtype=np.long) * u\n",
    "        tp_ones = np.ones(n_items, dtype=np.long)\n",
    "        tp_zeros = np.zeros(negative_num, dtype=np.long)\n",
    "        ratings = np.append(tp_ones, tp_zeros)\n",
    "        #     print(len(tp_users)),print(len(tp_items)),print(len(ratings))\n",
    "        tp = pd.DataFrame(\n",
    "            {\"user_ids\": tp_users, \"item_ids\": tp_items, \"ratings\": ratings}\n",
    "        )\n",
    "        total_interact = total_interact.append(tp)\n",
    "\n",
    "    total_interact = sklearn.utils.shuffle(total_interact)\n",
    "    return total_interact"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  divide data into train, validata and test sets, where validata set is in the train set  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_test_valid_by_orders(seq_data, validate_size=0.2, test_size=0.2):\n",
    "    print(\"split_test_valid_by_orders\")\n",
    "    seq_data[\"flag\"] == \"train\"\n",
    "    orders = seq_data[DEFAULT_ORDER_COL].unique()\n",
    "    total_size = len(orders)\n",
    "    validate_size = int(total_size * validate_size)\n",
    "    test_size = int(total_size * test_size)\n",
    "    np.sort(orders)\n",
    "    seq_data.loc[\n",
    "        seq_data[DEFAULT_ORDER_COL].isin(orders[total_size - test_size :]), \"flag\"\n",
    "    ] = \"test\"  # the last 20% of the total orders to be the test set\n",
    "    seq_data.loc[\n",
    "        seq_data[DEFAULT_ORDER_COL].isin(orders[: total_size - test_size]), \"flag\"\n",
    "    ] = \"train\"  # the other 80% of the total orders to be the test set\n",
    "    #     np.random.shuffle(orders[:validate_size])\n",
    "    # the last 20% of the training orders to be the validating set\n",
    "    unique_user_ids_test = seq_data[seq_data[\"flag\"] == \"test\"][\n",
    "        DEFAULT_USER_COL\n",
    "    ].unique()\n",
    "    unique_user_ids_train = seq_data[seq_data[\"flag\"] != \"test\"][\n",
    "        DEFAULT_USER_COL\n",
    "    ].unique()\n",
    "    unique_item_ids_test = seq_data[seq_data[\"flag\"] == \"test\"][\n",
    "        DEFAULT_ITEM_COL\n",
    "    ].unique()\n",
    "    unique_item_ids_train = seq_data[seq_data[\"flag\"] != \"test\"][\n",
    "        DEFAULT_ITEM_COL\n",
    "    ].unique()\n",
    "\n",
    "    seq_data.loc[\n",
    "        seq_data[DEFAULT_ORDER_COL].isin(\n",
    "            orders[total_size - test_size - validate_size : total_size - test_size]\n",
    "        ),\n",
    "        \"flag\",\n",
    "    ] = \"validate\"\n",
    "    # seq_data.drop('time', axis = 1, inplace = True)\n",
    "    print(\"labeling train validate test dataset finished \")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## filter data by count of users, items and orders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# group by group_col and filter filter_col that has less num unique() count\n",
    "def fiter_by_count(tp, group_col, filter_col, num):\n",
    "    ordercount = (\n",
    "        tp.groupby([group_col])[filter_col].nunique().rename(\"count\").reset_index()\n",
    "    )\n",
    "    filter_tp = tp[\n",
    "        tp[group_col].isin(ordercount[ordercount[\"count\"] >= num][group_col])\n",
    "    ]\n",
    "    return filter_tp\n",
    "\n",
    "\n",
    "# filter data by the minimum purcharce number of items and users\n",
    "def filter_triplets(tp, min_u_c=5, min_i_c=5, min_o_c=5):\n",
    "    print(\"filter data by the minimum purcharce number of items and users and orders\")\n",
    "    n_interact = len(tp.index)\n",
    "    n_orders = tp[DEFAULT_ORDER_COL].nunique()\n",
    "    n_users = tp[DEFAULT_USER_COL].nunique()\n",
    "    n_items = tp[DEFAULT_ITEM_COL].nunique()\n",
    "    print(\"before filter\", n_interact, n_orders, n_users, n_items)\n",
    "    # Filter users by mixmum number of orders\n",
    "    if min_o_c > 0:\n",
    "        tp = fiter_by_count(tp, DEFAULT_USER_COL, DEFAULT_ORDER_COL, min_o_c)\n",
    "\n",
    "    # Filter users by mixmum number of items\n",
    "    if min_i_c > 0:\n",
    "        tp = fiter_by_count(tp, DEFAULT_USER_COL, DEFAULT_ITEM_COL, min_i_c)\n",
    "\n",
    "    # Filter items by mixmum number of users\n",
    "    if min_u_c > 0:\n",
    "        tp = fiter_by_count(tp, DEFAULT_ITEM_COL, DEFAULT_USER_COL, min_u_c)\n",
    "\n",
    "    n_interact = len(tp.index)\n",
    "    n_orders = tp[DEFAULT_ORDER_COL].nunique()\n",
    "    n_users = tp[DEFAULT_USER_COL].nunique()\n",
    "    n_items = tp[DEFAULT_ITEM_COL].nunique()\n",
    "    print(\"after filter\", n_interact, n_orders, n_users, n_items)\n",
    "    # Update both usercount and itemcount after filtering\n",
    "    # usercount, itemcount = get_count(tp, 'user_ids'), get_count(tp, 'item_ids')\n",
    "    return tp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_train_to_files(data, data_base_dir, test_percent):\n",
    "\n",
    "    if test_percent < 1:\n",
    "        test_percent = int(test_percent * 100)\n",
    "    user_ids = data[DEFAULT_USER_COL].to_numpy(dtype=np.long)\n",
    "    item_ids = data[DEFAULT_ITEM_COL].to_numpy(dtype=np.long)\n",
    "    order_ids = data[DEFAULT_ORDER_COL].to_numpy(dtype=np.long)\n",
    "    timestamps = data[DEFAULT_TIMESTAMP_COL].to_numpy(dtype=np.long)\n",
    "    ratings = data[DEFAULT_RATING_COL].to_numpy(dtype=np.float32)\n",
    "    data_file = os.path.join(data_base_dir, \"temporal\", str(test_percent))\n",
    "    if not os.path.exists(data_file):\n",
    "        os.makedirs(data_file)\n",
    "    data_file = os.path.join(data_file, \"train.npz\")\n",
    "    np.savez_compressed(\n",
    "        data_file,\n",
    "        user_ids=user_ids,\n",
    "        item_ids=item_ids,\n",
    "        order_ids=order_ids,\n",
    "        timestamp=timestamps,\n",
    "        ratings=ratings,\n",
    "    )\n",
    "    print(\n",
    "        \"Data saving to file:\",\n",
    "        data_base_dir,\n",
    "        \"max_item_num:\",\n",
    "        np.max(item_ids),\n",
    "        \"max_user_num:\",\n",
    "        np.max(user_ids),\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_test_to_files(data, data_base_dir, test_percent, suffix):\n",
    "    if test_percent < 1:\n",
    "        test_percent = int(test_percent * 100)\n",
    "    user_ids = data[DEFAULT_USER_COL].to_numpy(dtype=np.long)\n",
    "    item_ids = data[DEFAULT_ITEM_COL].to_numpy(dtype=np.long)\n",
    "    ratings = data[DEFAULT_RATING_COL].to_numpy(dtype=np.float32)\n",
    "    data_file = os.path.join(data_base_dir, \"temporal\", str(test_percent))\n",
    "    if not os.path.exists(data_file):\n",
    "        os.makedirs(data_file)\n",
    "    data_file = os.path.join(data_file, suffix)\n",
    "    np.savez_compressed(\n",
    "        data_file, user_ids=user_ids, item_ids=item_ids, ratings=ratings,\n",
    "    )\n",
    "    print(\n",
    "        \"Data saving to file:\",\n",
    "        data_base_dir,\n",
    "        \"max_item_num:\",\n",
    "        np.max(item_ids),\n",
    "        \"max_user_num:\",\n",
    "        np.max(user_ids),\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "filter data by the minimum purcharce number of items and users and orders\n",
      "before filter 464118 77202 9238 7973\n",
      "after filter 170589 36433 2265 4181\n",
      "split_test_valid_by_orders\n",
      "labeling train validate test dataset finished \n",
      "Data saving to file: ../../datasets/ta-feng/ max_item_num: 9557615168355 max_user_num: 20002000\n",
      "Filling unigram table\n",
      "sampling negative items...\n",
      "sampling negative items...\n",
      "Data saving to file: ../../datasets/ta-feng/ max_item_num: 9557615168355 max_user_num: 20002000\n",
      "Data saving to file: ../../datasets/ta-feng/ max_item_num: 9557615168355 max_user_num: 20002000\n",
      "sampling negative items...\n",
      "sampling negative items...\n",
      "Data saving to file: ../../datasets/ta-feng/ max_item_num: 9557615168355 max_user_num: 20002000\n",
      "Data saving to file: ../../datasets/ta-feng/ max_item_num: 9557615168355 max_user_num: 20002000\n",
      "sampling negative items...\n",
      "sampling negative items...\n",
      "Data saving to file: ../../datasets/ta-feng/ max_item_num: 9557615168355 max_user_num: 20002000\n",
      "Data saving to file: ../../datasets/ta-feng/ max_item_num: 9557615168355 max_user_num: 20002000\n",
      "sampling negative items...\n",
      "sampling negative items...\n",
      "Data saving to file: ../../datasets/ta-feng/ max_item_num: 9557615168355 max_user_num: 20002000\n",
      "Data saving to file: ../../datasets/ta-feng/ max_item_num: 9557615168355 max_user_num: 20002000\n",
      "sampling negative items...\n",
      "sampling negative items...\n",
      "Data saving to file: ../../datasets/ta-feng/ max_item_num: 9557615168355 max_user_num: 20002000\n",
      "Data saving to file: ../../datasets/ta-feng/ max_item_num: 9557615168355 max_user_num: 20002000\n",
      "sampling negative items...\n"
     ]
    }
   ],
   "source": [
    "filter_tp = filter_triplets(\n",
    "    full_data, min_u_c=min_u_c, min_i_c=min_i_c, min_o_c=min_o_c\n",
    ")\n",
    "for test_percent in test_percents:\n",
    "    split_test_valid_by_orders(\n",
    "        filter_tp, validate_size=test_percent, test_size=test_percent\n",
    "    )\n",
    "\n",
    "    tp_train = filter_tp[filter_tp[\"flag\"] == \"train\"]\n",
    "    tp_validate = filter_tp[filter_tp[\"flag\"] == \"validate\"]\n",
    "    tp_test = filter_tp[filter_tp[\"flag\"] == \"test\"]\n",
    "    save_train_to_files(tp_train, data_base_dir, test_percent)\n",
    "\n",
    "    item_sampler = UnigramTable(tp_train[DEFAULT_ITEM_COL].value_counts().to_dict())\n",
    "    for i in range(10):\n",
    "        tp_validate_new = feed_neg_sample(tp_validate, 100, item_sampler)\n",
    "        tp_test_new = feed_neg_sample(tp_test, 100, item_sampler)\n",
    "        save_test_to_files(\n",
    "            tp_validate_new,\n",
    "            data_base_dir,\n",
    "            test_percent,\n",
    "            suffix=\"valid\" + \"_\" + str(i),\n",
    "        )\n",
    "        save_test_to_files(\n",
    "            tp_test_new, data_base_dir, test_percent, suffix=\"test\" + \"_\" + str(i),\n",
    "        )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
